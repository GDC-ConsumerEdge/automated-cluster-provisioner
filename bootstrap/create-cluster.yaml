steps:

- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: Read cluster intent, create cluster, and configure configsync
  script: |
    #!/usr/bin/env bash
    set +x

    function die() {
      echo "ERROR: $1"
      exit 1
    }

    [[ -z "${STORE_ID}" ]] && die "STORE_ID not set"

    apt-get update
    apt-get install -y gettext-base
    apt-get install -y csvtool

    TOKEN=$(gcloud secrets versions access latest --secret=$GIT_SECRET_ID --project $GIT_SECRETS_PROJECT_ID)
    git clone -b $SOURCE_OF_TRUTH_BRANCH https://oauth2:$TOKEN@$SOURCE_OF_TRUTH_REPO repo
    cp repo/$SOURCE_OF_TRUTH_PATH ./cluster-intent-registry.csv

    export CLUSTER_INTENT_ROW=$(awk -F , "\$1 == \"$STORE_ID\" || \$1 == \"\\\"$STORE_ID\\\"\"" cluster-intent-registry.csv)
    echo $CLUSTER_INTENT_ROW
    [[ -z "$CLUSTER_INTENT_ROW" ]] && die "Cluster intent not found for store $STORE_ID"
    export CLUSTER_INTENT_HEADER=$(head -1 cluster-intent-registry.csv)
    export CLUSTER_INTENT="$CLUSTER_INTENT_HEADER"$'\n'"$CLUSTER_INTENT_ROW"

    METADATA_PROJECT_ID=${METADATA_PROJECT_ID:-gdce-turnup}
    NODE_LOCATION=$(gcloud compute project-info describe --project ${METADATA_PROJECT_ID} \
        --format="value[](commonInstanceMetadata.items.${STORE_ID})" )
    [[ -z "$NODE_LOCATION" ]] && die "NODE_LOCATION cannot be fetched from metadata project"

    # Set parameters from cluster intent
    export MACHINE_PROJECT_ID=$(echo "$CLUSTER_INTENT" | csvtool namedcol "machine_project_id" - | csvtool drop 1 -)
    export FLEET_PROJECT_ID=$(echo "$CLUSTER_INTENT" | csvtool namedcol "fleet_project_id" - | csvtool drop 1 -)
    export CLUSTER_NAME=$(echo "$CLUSTER_INTENT" | csvtool namedcol "cluster_name" - | csvtool drop 1 -)
    export LOCATION=$(echo "$CLUSTER_INTENT" | csvtool namedcol "location" - | csvtool drop 1 -)
    export NODE_COUNT=$(echo "$CLUSTER_INTENT" | csvtool namedcol "node_count" - | csvtool drop 1 -)
    export CLUSTER_IPV4_CIDR=$(echo "$CLUSTER_INTENT" | csvtool namedcol "cluster_ipv4_cidr" - | csvtool drop 1 -)
    export SERVICES_IPV4_CIDR=$(echo "$CLUSTER_INTENT" | csvtool namedcol "services_ipv4_cidr" - | csvtool drop 1 -)
    export EXTERNAL_LOAD_BALANCER_IPV4_ADDRESS_POOLS=$(echo "$CLUSTER_INTENT" | csvtool namedcol "external_load_balancer_ipv4_address_pools" - | csvtool drop 1 -)
    export SYNC_REPO=$(echo "$CLUSTER_INTENT" | csvtool namedcol "sync_repo" - | csvtool drop 1 -)
    export SYNC_BRANCH=$(echo "$CLUSTER_INTENT" | csvtool namedcol "sync_branch" - | csvtool drop 1 -)
    export SYNC_DIR=$(echo "$CLUSTER_INTENT" | csvtool namedcol "sync_dir" - | csvtool drop 1 -)
    export SECRETS_PROJECT_ID=$(echo "$CLUSTER_INTENT" | csvtool namedcol "secrets_project_id" - | csvtool drop 1 -)
    export GIT_TOKEN_SECRETS_MANAGER_NAME=$(echo "$CLUSTER_INTENT" | csvtool namedcol "git_token_secrets_manager_name" - | csvtool drop 1 -)
    export ES_AGENT_SECRETS_MANAGER_NAME=$(echo "$CLUSTER_INTENT" | csvtool namedcol "es_agent_secrets_manager_name" - | csvtool drop 1 -)
    export CLUSTER_VERSION=$(echo "$CLUSTER_INTENT" | csvtool namedcol "cluster_version" - | csvtool drop 1 -)
    export RECREATE_ON_DELETE=$(echo "$CLUSTER_INTENT" | csvtool namedcol "recreate_on_delete" - | csvtool drop 1 -)

    GDCE_ZONE_STATE=$(gcloud compute project-info describe --project ${METADATA_PROJECT_ID} \
        --format="value[](commonInstanceMetadata.items.${NODE_LOCATION}-GDCE_ZONE_STATE)" )

    if [[ "${GDCE_ZONE_STATE}" == "STATE_TURNED_UP_WITH_CLUSTER" ]]; then
      if [[ "${RECREATE_ON_DELETE}" == "false" ]]; then
        echo "Zone ${NODE_LOCATION} is already marked as STATE_TURNED_UP_WITH_CLUSTER, exiting."
        exit 0
      fi

      echo "Zone ${NODE_LOCATION} is already marked as STATE_TURNED_UP_WITH_CLUSTER, recreating cluster."
    fi

    if [ -n "${EDGE_CONTAINER_API_ENDPOINT_OVERRIDE:-}" ]; then
      echo "Setting api_endpoint_overrides/edgecontainer to $EDGE_CONTAINER_API_ENDPOINT_OVERRIDE"
      gcloud config set api_endpoint_overrides/edgecontainer $EDGE_CONTAINER_API_ENDPOINT_OVERRIDE
    fi

    if [ -n "${GKEHUB_API_ENDPOINT_OVERRIDE:-}" ]; then
      echo "Setting api_endpoint_overrides/gkehub to $GKEHUB_API_ENDPOINT_OVERRIDE"
      gcloud config set api_endpoint_overrides/gkehub $GKEHUB_API_ENDPOINT_OVERRIDE
    fi

    gcloud edge-cloud container clusters describe $CLUSTER_NAME --location $LOCATION \
        --project $FLEET_PROJECT_ID

    if [ $? -eq 0 ]; then
      echo "Cluster already created, skipping to next step."
    else
      echo "Creating cluster"
      gcloud edge-cloud container clusters create $CLUSTER_NAME \
          --control-plane-node-location=$NODE_LOCATION \
          --control-plane-node-count=$NODE_COUNT \
          --cluster-ipv4-cidr=$CLUSTER_IPV4_CIDR \
          --services-ipv4-cidr=$SERVICES_IPV4_CIDR \
          --external-lb-ipv4-address-pools=$EXTERNAL_LOAD_BALANCER_IPV4_ADDRESS_POOLS \
          --control-plane-shared-deployment-policy=ALLOWED \
          --location=$LOCATION \
          --project=$FLEET_PROJECT_ID \
          --release-channel=NONE \
          --version $CLUSTER_VERSION
          # --offline-reboot-ttl=7d \

      [[ $? -ne 0 ]] && die "Cluster Creation Failed: Failure from gcloud \
          edge-cloud container clusters ..."

    fi

    export KUBECONFIG="$(pwd)/gateway-kubeconfig"
    gcloud container fleet memberships get-credentials $CLUSTER_NAME --project $FLEET_PROJECT_ID

    gsutil cp gs://$CLUSTER_INTENT_BUCKET/apply-spec.yaml.template .
    gsutil cp gs://$CLUSTER_INTENT_BUCKET/cluster-secret-store.yaml.template .

    envsubst < apply-spec.yaml.template > apply-spec.yaml
    envsubst < cluster-secret-store.yaml.template > cluster-secret-store.yaml

    gcloud secrets versions access latest --secret=$GIT_TOKEN_SECRETS_MANAGER_NAME \
        --project $SECRETS_PROJECT_ID >> $(pwd)/git-creds

    kubectl create ns config-management-system --dry-run=client -o yaml | kubectl apply -f -

    kubectl create secret generic git-creds --namespace="config-management-system" \
        --from-literal=username=default --from-file=token=$(pwd)/git-creds \
        --dry-run=client -o yaml | kubectl apply -f -

    gcloud beta container fleet config-management apply --membership=$CLUSTER_NAME \
        --config=./apply-spec.yaml --project $FLEET_PROJECT_ID

    gcloud secrets versions access latest --secret=$ES_AGENT_SECRETS_MANAGER_NAME \
        --project $SECRETS_PROJECT_ID >> $(pwd)/es-agent.json

    kubectl create ns external-secrets --dry-run=client -o yaml | kubectl apply -f -

    kubectl create secret generic gcp-store-creds --from-file=$(pwd)/es-agent.json \
        -n external-secrets

    # Wait up to 2 minutes for External Secrets CRDs
    tries=0
    until [ "$tries" -ge 8 ]
    do
      kubectl get crd/externalsecrets.external-secrets.io >/dev/null 2>&1 && break
      tries=$((tries+1))
      sleep 15
    done
    [[ "$tries" -ge 8 ]] && die "Cluster Creation Failed: External Secrets \
          CRDS failed to deploy. Please confirm External Secrets deployment"

    kubectl wait --for=condition=available --timeout=30s apiservice/v1beta1.external-secrets.io

    # Wait up to 5 minutes for Cluster Secret Store to deploy
    tries=0
    until [ "$tries" -ge 20 ]
    do
      kubectl apply -f cluster-secret-store.yaml && break
      tries=$((tries+1))
      sleep 15
    done
    [[ "$tries" -ge 20 ]] && die "Cluster Creation Failed: External Secrets Cluster \
          Secret Store failed to deploy. Please confirm External Secrets deployment"

    if [ -z "${SKIP_HEALTH_CHECK}" ]; then
      count=0
      max_retries=240 # 1200s/20min
      echo "Waiting for health check resource to be created"
      while [[ ${count} -lt ${max_retries} ]]; do
        kubectl get healthchecks.validator.gdc.gke.io/default >/dev/null 2>&1 && break
        echo -n .
        sleep 5
        ((count++))
      done
      [[ ${count} -ge ${max_retries} ]] && die "Health check resource not created after 20min"

      kubectl wait healthchecks.validator.gdc.gke.io/default --for condition=PlatformHealthy \
          --timeout=20m || die "Platform is not healthy after 20m"
      kubectl wait healthchecks.validator.gdc.gke.io/default --for condition=WorkloadsHealthy \
          --timeout=20m || die "Workloads are not healthy after 20m"
    fi
    
    gcloud compute project-info add-metadata \
        --metadata=${NODE_LOCATION}-GDCE_ZONE_STATE=STATE_TURNED_UP_WITH_CLUSTER \
        --project=$METADATA_PROJECT_ID || \
        die "Failed to update the cluster status in metadata"

    echo "Cluster Creation Succeeded: $CLUSTER_NAME"

  env:
  - 'STORE_ID=$_STORE_ID'
  - 'EDGE_CONTAINER_API_ENDPOINT_OVERRIDE=$_EDGE_CONTAINER_API_ENDPOINT_OVERRIDE'
  - 'GKEHUB_API_ENDPOINT_OVERRIDE=$_GKEHUB_API_ENDPOINT_OVERRIDE'
  - 'CLUSTER_INTENT_BUCKET=$_CLUSTER_INTENT_BUCKET'
  - 'SOURCE_OF_TRUTH_REPO=$_SOURCE_OF_TRUTH_REPO'
  - 'SOURCE_OF_TRUTH_BRANCH=$_SOURCE_OF_TRUTH_BRANCH'
  - 'SOURCE_OF_TRUTH_PATH=$_SOURCE_OF_TRUTH_PATH'
  - 'GIT_SECRET_ID=$_GIT_SECRET_ID'
  - 'GIT_SECRETS_PROJECT_ID=$_GIT_SECRETS_PROJECT_ID'
  - 'METADATA_PROJECT_ID=$_METADATA_PROJECT_ID'
timeout: 14400s
options:
  logging: CLOUD_LOGGING_ONLY
